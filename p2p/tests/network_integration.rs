//! Integration tests for P2P networking layer.
//!
//! These tests use the deterministic runtime from commonware-runtime to test
//! actual network service creation and message passing.

use std::time::Duration;

use commonware_codec::ReadExt;
use commonware_cryptography::{Signer, ed25519};
use commonware_runtime::{Clock, Runner};
use consensus::crypto::aggregated::PeerId;

use p2p::config::{P2PConfig, ValidatorPeerInfo};
use p2p::message::channels;
use p2p::network::NetworkService;

/// Create a test P2P config for a given node.
fn create_test_config(port: u16) -> P2PConfig {
    P2PConfig {
        listen_addr: format!("127.0.0.1:{}", port).parse().unwrap(),
        external_addr: format!("127.0.0.1:{}", port).parse().unwrap(),
        validators: vec![],
        cluster_id: "test-cluster".to_string(),
        max_message_size: 1024 * 1024,
        message_backlog: 1024,
        consensus_rate_per_second: 10000,
        tx_rate_per_second: 50000,
    }
}

/// Create a test logger that discards output.
fn create_test_logger() -> slog::Logger {
    slog::Logger::root(slog::Discard, slog::o!())
}

/// Test NetworkService creation and verify all components initialized.
#[test]
fn test_network_service_creation_with_receivers() {
    let executor = commonware_runtime::deterministic::Runner::default();

    executor.start(|ctx| async move {
        let signer = ed25519::PrivateKey::from_seed(42);
        let config = create_test_config(9000);
        let logger = create_test_logger();

        let (mut network, receivers) =
            NetworkService::new(ctx.clone(), signer.clone(), config, logger).await;

        // Assert: public key matches signer
        assert_eq!(network.public_key(), signer.public_key());

        // Assert: all three receiver channels exist and are valid
        // (consensus, tx, sync)
        let _consensus_recv = receivers.consensus;
        let _tx_recv = receivers.tx;
        let _sync_recv = receivers.sync;

        network.shutdown();
    });
}

/// Test NetworkService returns deterministic public key from seed.
#[test]
fn test_network_service_deterministic_key_generation() {
    let executor1 = commonware_runtime::deterministic::Runner::default();
    let executor2 = commonware_runtime::deterministic::Runner::default();

    // Run same seed twice - should get same public key
    let mut pk1: Option<ed25519::PublicKey> = None;
    let mut pk2: Option<ed25519::PublicKey> = None;

    executor1.start(|ctx| {
        let pk_ref = &mut pk1;
        async move {
            let signer = ed25519::PrivateKey::from_seed(12345);
            let config = create_test_config(9010);
            let logger = create_test_logger();

            let (network, _) = NetworkService::new(ctx, signer, config, logger).await;
            *pk_ref = Some(network.public_key());
        }
    });

    executor2.start(|ctx| {
        let pk_ref = &mut pk2;
        async move {
            let signer = ed25519::PrivateKey::from_seed(12345); // Same seed
            let config = create_test_config(9011);
            let logger = create_test_logger();

            let (network, _) = NetworkService::new(ctx, signer, config, logger).await;
            *pk_ref = Some(network.public_key());
        }
    });

    // Assert: same seed produces same key
    assert_eq!(pk1, pk2);
}

/// Test that different seeds produce different public keys.
#[test]
fn test_different_seeds_produce_different_keys() {
    let executor = commonware_runtime::deterministic::Runner::default();

    executor.start(|ctx| async move {
        let signer1 = ed25519::PrivateKey::from_seed(1);
        let signer2 = ed25519::PrivateKey::from_seed(2);

        // Assert: different seeds must produce different keys
        assert_ne!(signer1.public_key(), signer2.public_key());

        let config1 = create_test_config(9007);
        let config2 = create_test_config(9008);
        let logger = create_test_logger();

        let (network1, _) =
            NetworkService::new(ctx.clone(), signer1, config1, logger.clone()).await;

        let (network2, _) = NetworkService::new(ctx, signer2, config2, logger).await;

        // Assert: network public keys reflect the signer keys
        assert_ne!(network1.public_key(), network2.public_key());
    });
}

/// Test shutdown is idempotent - can be called multiple times.
#[test]
fn test_shutdown_idempotent() {
    let executor = commonware_runtime::deterministic::Runner::default();

    executor.start(|ctx| async move {
        let signer = ed25519::PrivateKey::from_seed(456);
        let config = create_test_config(9002);
        let logger = create_test_logger();

        let (mut network, _) = NetworkService::new(ctx, signer, config, logger).await;

        // First shutdown should succeed
        network.shutdown();
        // Second shutdown should not panic (idempotent)
        network.shutdown();
        // Third time for good measure
        network.shutdown();
    });
}

/// Test that bootstrapper peer info is correctly parsed from config.
#[test]
fn test_bootstrapper_parsing_into_network() {
    let executor = commonware_runtime::deterministic::Runner::default();

    executor.start(|ctx| async move {
        // Create a known bootstrap peer
        let bootstrap_signer = ed25519::PrivateKey::from_seed(100);
        let bootstrap_pk = bootstrap_signer.public_key();
        let bootstrap_pk_hex = hex::encode(bootstrap_pk.as_ref());
        let bootstrap_addr: std::net::SocketAddr = "127.0.0.1:9999".parse().unwrap();

        // Verify the hex encoding produces correct length
        assert_eq!(bootstrap_pk_hex.len(), 64); // 32 bytes = 64 hex chars

        let validator = ValidatorPeerInfo {
            ed25519_public_key: bootstrap_pk_hex.clone(),
            address: Some(bootstrap_addr),
            bls_peer_id: PeerId::default(),
        };

        // Assert: parsing the public key back succeeds
        let parsed_bytes = validator.parse_public_key_bytes();
        assert!(parsed_bytes.is_some());
        let parsed_bytes = parsed_bytes.unwrap();

        // Assert: parsed bytes match original
        assert_eq!(parsed_bytes.as_slice(), bootstrap_pk.as_ref());

        // Assert: can reconstruct the public key
        let reconstructed_pk = ed25519::PublicKey::read(&mut parsed_bytes.as_slice());
        assert!(reconstructed_pk.is_ok());
        assert_eq!(reconstructed_pk.unwrap(), bootstrap_pk);

        // Now verify the service accepts this config
        let mut config = create_test_config(9003);
        config.validators.push(validator);

        let signer = ed25519::PrivateKey::from_seed(200);
        let logger = create_test_logger();

        let (mut network, _) = NetworkService::new(ctx, signer, config, logger).await;

        // Assert: service created successfully with bootstrapper
        network.shutdown();
    });
}

/// Test that invalid bootstrapper hex is handled gracefully.
#[test]
fn test_invalid_bootstrapper_hex_handled() {
    let validator = ValidatorPeerInfo {
        ed25519_public_key: "not_valid_hex_at_all".to_string(),
        address: Some("127.0.0.1:9999".parse().unwrap()),
        bls_peer_id: PeerId::default(),
    };

    // Assert: parsing fails gracefully (returns None, doesn't panic)
    assert!(validator.parse_public_key_bytes().is_none());
}

/// Test that short public key hex is rejected.
#[test]
fn test_short_public_key_rejected() {
    let validator = ValidatorPeerInfo {
        // Only 16 bytes (32 hex chars) instead of 32 bytes (64 hex chars)
        ed25519_public_key: "0123456789abcdef0123456789abcdef".to_string(),
        address: Some("127.0.0.1:9999".parse().unwrap()),
        bls_peer_id: PeerId::default(),
    };

    // Assert: short key is rejected
    assert!(validator.parse_public_key_bytes().is_none());
}

// Message serialization tests removed - Transaction requires complex construction.
// Serialization is tested in p2p/src/message.rs unit tests.

/// Test channel IDs are distinct.
#[test]
fn test_channel_ids_are_distinct() {
    // Assert: each channel has a unique ID
    assert_ne!(channels::CONSENSUS, channels::TRANSACTIONS);
    assert_ne!(channels::CONSENSUS, channels::BLOCK_SYNC);
    assert_ne!(channels::TRANSACTIONS, channels::BLOCK_SYNC);
}

/// Test two network nodes can be created on same runtime with different ports.
/// This test verifies that:
/// 1. Two nodes can coexist with unique identities
/// 2. They can reference each other's public keys for targeted messages
/// 3. Messages can be sent (network delivery in deterministic runtime is simulated)
#[test]
fn test_two_nodes_on_same_runtime() {
    let executor = commonware_runtime::deterministic::Runner::default();

    executor.start(|ctx| async move {
        let signer1 = ed25519::PrivateKey::from_seed(1);
        let signer2 = ed25519::PrivateKey::from_seed(2);

        // Set up mutual bootstrappers so nodes know about each other
        let pk1 = signer1.public_key();
        let pk2 = signer2.public_key();
        let pk1_hex = hex::encode(pk1.as_ref());
        let pk2_hex = hex::encode(pk2.as_ref());

        let mut config1 = create_test_config(9100);
        config1.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk2_hex.clone(),
            address: Some("127.0.0.1:9101".parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let mut config2 = create_test_config(9101);
        config2.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk1_hex.clone(),
            address: Some("127.0.0.1:9100".parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let logger = create_test_logger();

        // Create two separate network services
        let (mut network1, receivers1) =
            NetworkService::new(ctx.clone(), signer1.clone(), config1, logger.clone()).await;

        let (mut network2, receivers2) =
            NetworkService::new(ctx.clone(), signer2.clone(), config2, logger).await;

        // Assert: both nodes have unique public keys
        assert_ne!(network1.public_key(), network2.public_key());
        assert_eq!(network1.public_key(), pk1);
        assert_eq!(network2.public_key(), pk2);

        // Assert: receivers are properly created
        // These can be used to receive messages in a real scenario
        let _consensus_recv1 = receivers1.consensus;
        let _tx_recv1 = receivers1.tx;
        let _sync_recv1 = receivers1.sync;

        let mut consensus_recv2 = receivers2.consensus;
        let _tx_recv2 = receivers2.tx;
        let _sync_recv2 = receivers2.sync;

        // Test: send targeted messages to each other
        // In deterministic runtime, actual network delivery depends on peer discovery
        let test_msg_1_to_2 = b"Hello from node 1 to node 2".to_vec();
        let test_msg_2_to_1 = b"Hello from node 2 to node 1".to_vec();

        // Send from node1 to node2 (targeted by public key)
        network1
            .broadcast_consensus(test_msg_1_to_2.clone(), vec![pk2.clone()])
            .await;

        // Send from node2 to node1 (targeted by public key)
        network2
            .broadcast_consensus(test_msg_2_to_1.clone(), vec![pk1.clone()])
            .await;

        // Test: broadcast to all (empty recipients = all)
        network1
            .broadcast_transaction(b"broadcast_tx_from_1".to_vec(), vec![])
            .await;
        network2.send_sync(b"sync_from_2".to_vec(), vec![]).await;

        // Attempt to receive messages using tokio::select! with a manual timeout
        // This avoids the lifetime issues with ctx.timeout()
        use commonware_p2p::Receiver;

        // Use select! to race between receiving and a timeout
        let receive_result = tokio::select! {
            biased;

            // Try to receive message from node1
            result = consensus_recv2.recv() => Some(result),

            // Timeout after 500ms (in deterministic runtime, this may resolve immediately)
            _ = ctx.sleep(Duration::from_millis(500)) => None,
        };

        // Verify the result - in deterministic runtime, peers may or may not connect
        // The test verifies the mechanism is correct when messages arrive
        match receive_result {
            Some(Ok((sender_pk, msg_bytes))) => {
                // Successfully received! Verify content
                assert_eq!(sender_pk, pk1, "Sender should be node1");
                assert_eq!(
                    msg_bytes.as_ref(),
                    test_msg_1_to_2.as_slice(),
                    "Message content should match"
                );
                println!("✓ Message successfully received from node1 to node2");
            }
            Some(Err(e)) => {
                // Receiver error (channel closed, etc)
                // This is acceptable - peers may not have connected in time
                println!(
                    "Receiver returned error (peers may not be connected): {:?}",
                    e
                );
            }
            None => {
                // Timeout - peers didn't connect in time
                // This is expected in deterministic runtime without real network
                // The test still validates the send/receive mechanism code paths
                println!("Timeout waiting for message - expected in deterministic runtime");
            }
        }

        // Cleanup
        network1.shutdown();
        network2.shutdown();
    });
}

/// Test config with peer bootstrappers pointing to each other.
#[test]
fn test_mutual_bootstrappers() {
    let executor = commonware_runtime::deterministic::Runner::default();

    executor.start(|ctx| async move {
        let signer1 = ed25519::PrivateKey::from_seed(1001);
        let signer2 = ed25519::PrivateKey::from_seed(1002);

        let pk1 = signer1.public_key();
        let pk2 = signer2.public_key();

        let pk1_hex = hex::encode(pk1.as_ref());
        let pk2_hex = hex::encode(pk2.as_ref());

        // Node 1 knows about Node 2
        let mut config1 = create_test_config(9200);
        config1.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk2_hex.clone(),
            address: Some("127.0.0.1:9201".parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        // Node 2 knows about Node 1
        let mut config2 = create_test_config(9201);
        config2.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk1_hex.clone(),
            address: Some("127.0.0.1:9200".parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let logger = create_test_logger();

        // Assert: both can be created with mutual references
        let (network1, _) =
            NetworkService::new(ctx.clone(), signer1, config1, logger.clone()).await;
        let (network2, _) = NetworkService::new(ctx, signer2, config2, logger).await;

        // Assert: public keys match expected
        assert_eq!(network1.public_key(), pk1);
        assert_eq!(network2.public_key(), pk2);

        drop(network1);
        drop(network2);
    });
}

/// Test actual message delivery between two nodes using real network I/O.
/// This test uses the tokio-backed runtime which performs real TCP connections.
///
/// NOTE: This test requires available ports and may be flaky if ports are in use.
#[test]
fn test_real_message_delivery_between_nodes() {
    use commonware_p2p::Receiver;

    // Use tokio runtime for real network I/O
    let executor = commonware_runtime::tokio::Runner::default();

    executor.start(|ctx| async move {
        let signer1 = ed25519::PrivateKey::from_seed(2001);
        let signer2 = ed25519::PrivateKey::from_seed(2002);

        let pk1 = signer1.public_key();
        let pk2 = signer2.public_key();
        let pk1_hex = hex::encode(pk1.as_ref());
        let pk2_hex = hex::encode(pk2.as_ref());

        // Use high port numbers to avoid conflicts
        let port1: u16 = 19100;
        let port2: u16 = 19101;

        // Set up mutual bootstrappers so nodes know about each other
        let mut config1 = create_test_config(port1);
        config1.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk2_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port2).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let mut config2 = create_test_config(port2);
        config2.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk1_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port1).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let logger = create_test_logger();

        // Create two network services
        let (mut network1, _receivers1) =
            NetworkService::new(ctx.clone(), signer1.clone(), config1, logger.clone()).await;

        let (network2, mut receivers2) =
            NetworkService::new(ctx.clone(), signer2.clone(), config2, logger).await;

        // Give peers time to discover each other and establish connections
        ctx.sleep(Duration::from_millis(1000)).await;

        // Send message from node1 to node2
        let test_msg = b"Hello from node 1 to node 2 - real network!".to_vec();
        network1
            .broadcast_consensus(test_msg.clone(), vec![pk2.clone()])
            .await;

        // Try to receive with timeout
        let receive_result = tokio::select! {
            biased;

            result = receivers2.consensus.recv() => Some(result),

            _ = ctx.sleep(Duration::from_secs(5)) => None,
        };

        // Verify message was received
        match receive_result {
            Some(Ok((sender_pk, msg_bytes))) => {
                assert_eq!(sender_pk, pk1, "Sender should be node1");
                assert_eq!(
                    msg_bytes.as_ref(),
                    test_msg.as_slice(),
                    "Message content should match"
                );
                println!("✓ Real message successfully delivered from node1 to node2");
            }
            Some(Err(e)) => {
                panic!("Receiver error: {:?}", e);
            }
            None => {
                panic!("Timeout waiting for message - peers may not have connected");
            }
        }

        // Cleanup - drop networks to release ports
        drop(network1);
        drop(network2);
        // Wait for socket cleanup
        ctx.sleep(Duration::from_millis(100)).await;
    });
}

/// Test bidirectional message delivery - both nodes send and receive.
#[test]
fn test_bidirectional_message_delivery() {
    use commonware_p2p::Receiver;

    let executor = commonware_runtime::tokio::Runner::default();

    executor.start(|ctx| async move {
        let signer1 = ed25519::PrivateKey::from_seed(3001);
        let signer2 = ed25519::PrivateKey::from_seed(3002);

        let pk1 = signer1.public_key();
        let pk2 = signer2.public_key();
        let pk1_hex = hex::encode(pk1.as_ref());
        let pk2_hex = hex::encode(pk2.as_ref());

        let port1: u16 = 19200;
        let port2: u16 = 19201;

        let mut config1 = create_test_config(port1);
        config1.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk2_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port2).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let mut config2 = create_test_config(port2);
        config2.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk1_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port1).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let logger = create_test_logger();

        let (mut network1, mut receivers1) =
            NetworkService::new(ctx.clone(), signer1.clone(), config1, logger.clone()).await;
        let (mut network2, mut receivers2) =
            NetworkService::new(ctx.clone(), signer2.clone(), config2, logger).await;

        ctx.sleep(Duration::from_millis(1000)).await;

        // Send messages in both directions
        let msg1_to_2 = b"Message from node1 to node2".to_vec();
        let msg2_to_1 = b"Message from node2 to node1".to_vec();

        network1
            .broadcast_consensus(msg1_to_2.clone(), vec![pk2.clone()])
            .await;
        network2
            .broadcast_consensus(msg2_to_1.clone(), vec![pk1.clone()])
            .await;

        // Receive both messages
        let (result1, result2) = tokio::join!(
            tokio::time::timeout(Duration::from_secs(5), receivers2.consensus.recv()),
            tokio::time::timeout(Duration::from_secs(5), receivers1.consensus.recv()),
        );

        // Verify node2 received message from node1
        match result1 {
            Ok(Ok((sender, msg))) => {
                assert_eq!(sender, pk1);
                assert_eq!(msg.as_ref(), msg1_to_2.as_slice());
            }
            _ => panic!("Node2 failed to receive message from node1"),
        }

        // Verify node1 received message from node2
        match result2 {
            Ok(Ok((sender, msg))) => {
                assert_eq!(sender, pk2);
                assert_eq!(msg.as_ref(), msg2_to_1.as_slice());
            }
            _ => panic!("Node1 failed to receive message from node2"),
        }

        drop(network1);
        drop(network2);
        ctx.sleep(Duration::from_millis(100)).await;
    });
}

/// Test transaction channel message delivery.
#[test]
fn test_transaction_channel_delivery() {
    use commonware_p2p::Receiver;

    let executor = commonware_runtime::tokio::Runner::default();

    executor.start(|ctx| async move {
        let signer1 = ed25519::PrivateKey::from_seed(4001);
        let signer2 = ed25519::PrivateKey::from_seed(4002);

        let pk1 = signer1.public_key();
        let pk2 = signer2.public_key();
        let pk1_hex = hex::encode(pk1.as_ref());
        let pk2_hex = hex::encode(pk2.as_ref());

        let port1: u16 = 19350;
        let port2: u16 = 19351;

        let mut config1 = create_test_config(port1);
        config1.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk2_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port2).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let mut config2 = create_test_config(port2);
        config2.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk1_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port1).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let logger = create_test_logger();

        let (mut network1, _receivers1) =
            NetworkService::new(ctx.clone(), signer1.clone(), config1, logger.clone()).await;
        let (network2, mut receivers2) =
            NetworkService::new(ctx.clone(), signer2.clone(), config2, logger).await;

        ctx.sleep(Duration::from_millis(1000)).await;

        let tx_msg = b"Transaction data for gossip".to_vec();
        network1
            .broadcast_transaction(tx_msg.clone(), vec![pk2.clone()])
            .await;

        let result = tokio::time::timeout(Duration::from_secs(5), receivers2.tx.recv()).await;

        match result {
            Ok(Ok((sender, msg))) => {
                assert_eq!(sender, pk1);
                assert_eq!(msg.as_ref(), tx_msg.as_slice());
            }
            _ => panic!("Failed to receive transaction message"),
        }

        drop(network1);
        drop(network2);
        ctx.sleep(Duration::from_millis(100)).await;
    });
}

/// Test sync channel message delivery.
#[test]
fn test_sync_channel_delivery() {
    use commonware_p2p::Receiver;

    let executor = commonware_runtime::tokio::Runner::default();

    executor.start(|ctx| async move {
        let signer1 = ed25519::PrivateKey::from_seed(5001);
        let signer2 = ed25519::PrivateKey::from_seed(5002);

        let pk1 = signer1.public_key();
        let pk2 = signer2.public_key();
        let pk1_hex = hex::encode(pk1.as_ref());
        let pk2_hex = hex::encode(pk2.as_ref());

        let port1: u16 = 19400;
        let port2: u16 = 19401;

        let mut config1 = create_test_config(port1);
        config1.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk2_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port2).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let mut config2 = create_test_config(port2);
        config2.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk1_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port1).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let logger = create_test_logger();

        let (mut network1, _receivers1) =
            NetworkService::new(ctx.clone(), signer1.clone(), config1, logger.clone()).await;
        let (network2, mut receivers2) =
            NetworkService::new(ctx.clone(), signer2.clone(), config2, logger).await;

        ctx.sleep(Duration::from_millis(1000)).await;

        let sync_msg = b"Block sync request/response data".to_vec();
        network1
            .send_sync(sync_msg.clone(), vec![pk2.clone()])
            .await;

        let result = tokio::time::timeout(Duration::from_secs(5), receivers2.sync.recv()).await;

        match result {
            Ok(Ok((sender, msg))) => {
                assert_eq!(sender, pk1);
                assert_eq!(msg.as_ref(), sync_msg.as_slice());
            }
            _ => panic!("Failed to receive sync message"),
        }

        drop(network1);
        drop(network2);
        ctx.sleep(Duration::from_millis(100)).await;
    });
}

/// Test broadcast to all nodes (empty recipients list).
#[test]
fn test_broadcast_to_all_nodes() {
    use commonware_p2p::Receiver;

    let executor = commonware_runtime::tokio::Runner::default();

    executor.start(|ctx| async move {
        let signer1 = ed25519::PrivateKey::from_seed(6001);
        let signer2 = ed25519::PrivateKey::from_seed(6002);
        let signer3 = ed25519::PrivateKey::from_seed(6003);

        let pk1 = signer1.public_key();
        let pk2 = signer2.public_key();
        let pk3 = signer3.public_key();
        let pk1_hex = hex::encode(pk1.as_ref());
        let pk2_hex = hex::encode(pk2.as_ref());
        let pk3_hex = hex::encode(pk3.as_ref());

        let port1: u16 = 19800;
        let port2: u16 = 19801;
        let port3: u16 = 19802;

        // All nodes know about each other
        let mut config1 = create_test_config(port1);
        config1.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk2_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port2).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });
        config1.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk3_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port3).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let mut config2 = create_test_config(port2);
        config2.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk1_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port1).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });
        config2.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk3_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port3).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let mut config3 = create_test_config(port3);
        config3.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk1_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port1).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });
        config3.validators.push(ValidatorPeerInfo {
            ed25519_public_key: pk2_hex.clone(),
            address: Some(format!("127.0.0.1:{}", port2).parse().unwrap()),
            bls_peer_id: PeerId::default(),
        });

        let logger = create_test_logger();

        let (mut network1, _receivers1) =
            NetworkService::new(ctx.clone(), signer1.clone(), config1, logger.clone()).await;
        let (network2, mut receivers2) =
            NetworkService::new(ctx.clone(), signer2.clone(), config2, logger.clone()).await;
        let (network3, mut receivers3) =
            NetworkService::new(ctx.clone(), signer3.clone(), config3, logger).await;

        // Give all peers time to discover each other
        // 3-node discovery takes longer than 2-node
        ctx.sleep(Duration::from_millis(3000)).await;

        // Broadcast from node1 to all (empty recipients = broadcast to all)
        let broadcast_msg = b"Broadcast message to all nodes".to_vec();
        network1
            .broadcast_consensus(broadcast_msg.clone(), vec![])
            .await;

        // Both node2 and node3 should receive the message
        let (result2, result3) = tokio::join!(
            tokio::time::timeout(Duration::from_secs(5), receivers2.consensus.recv()),
            tokio::time::timeout(Duration::from_secs(5), receivers3.consensus.recv()),
        );

        match result2 {
            Ok(Ok((sender, msg))) => {
                assert_eq!(sender, pk1);
                assert_eq!(msg.as_ref(), broadcast_msg.as_slice());
            }
            _ => panic!("Node2 failed to receive broadcast"),
        }

        match result3 {
            Ok(Ok((sender, msg))) => {
                assert_eq!(sender, pk1);
                assert_eq!(msg.as_ref(), broadcast_msg.as_slice());
            }
            _ => panic!("Node3 failed to receive broadcast"),
        }

        drop(network1);
        drop(network2);
        drop(network3);
        ctx.sleep(Duration::from_millis(100)).await;
    });
}
